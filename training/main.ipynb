{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef591e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Config file not found: c:\\Users\\ryanp\\Personal Projects\\mlm25_mavedb\\training\\src\\aasp\\data_handler\\src\\aasp\\data_handler\\config.yaml",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maasp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_handler\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maasp_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AASPDataset\n\u001b[32m      4\u001b[39m config_path = \u001b[33m\"\u001b[39m\u001b[33msrc/aasp/data_handler/config.yaml\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m cfg = \u001b[43mAASPConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m handler = AASPDataHandler(cfg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanp\\Personal Projects\\mlm25_mavedb\\training\\src\\aasp\\data_handler\\data_handler.py:29\u001b[39m, in \u001b[36mAASPConfig.__init__\u001b[39m\u001b[34m(self, config_path)\u001b[39m\n\u001b[32m     27\u001b[39m p = Path(\u001b[34m__file__\u001b[39m).parent / config_path\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m p.exists():\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConfig file not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(p, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     31\u001b[39m     cfg = yaml.safe_load(f) \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Config file not found: c:\\Users\\ryanp\\Personal Projects\\mlm25_mavedb\\training\\src\\aasp\\data_handler\\src\\aasp\\data_handler\\config.yaml"
     ]
    }
   ],
   "source": [
    "from src.aasp.data_handler.data_handler import AASPConfig, AASPDataHandler\n",
    "from src.aasp.data_handler.aasp_dataset import AASPDataset\n",
    "\n",
    "config_path = \"config.yaml\"\n",
    "cfg = AASPConfig(config_path)\n",
    "handler = AASPDataHandler(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfbf62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    k for k, v in getattr(cfg, \"features\", {}).items()\n",
    "    if v and k in {\"ref_embedding\", \"alt_embedding\", \"biotype\", \"consequence\", \"ref_long\", \"alt_long\", \"scoreset\"}\n",
    "]\n",
    "cat_config = getattr(cfg, \"categorical_config\", {})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbf69d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m records = \u001b[43mhandler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m val_frac = cfg.parameters.get(\u001b[33m\"\u001b[39m\u001b[33mval_frac\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0.15\u001b[39m)\n\u001b[32m      3\u001b[39m val_size = \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(records) * val_frac)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanp\\Personal Projects\\mlm25_mavedb\\training\\src\\aasp\\data_handler\\data_handler.py:76\u001b[39m, in \u001b[36mAASPDataHandler.load_pickle\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m     73\u001b[39m src = path \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.file_path\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# 2) load the pickle\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[43mp\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     77\u001b[39m     obj = pickle.load(f)\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# 3) normalize to list-of-dicts\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m#    - case A: already list-of-dicts\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'p' is not defined"
     ]
    }
   ],
   "source": [
    "records = handler.load_pickle(cfg.file_path)\n",
    "val_frac = cfg.parameters.get(\"val_frac\", 0.15)\n",
    "val_size = int(len(records) * val_frac)\n",
    "train_records = records[:len(records) - val_size]\n",
    "val_records = records[len(records) - val_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba730b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = {k: handler.fit_vocab(train_records, k) for k in cat_config}\n",
    "for k, vocab in vocabs.items():\n",
    "    print(f\"Vocab for {k}: {len(vocab)} classes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ac4c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AASPDataset(\n",
    "    config_path=config_path,\n",
    "    fields=selected_features,\n",
    "    fuse_mode=cfg.fuse_mode,\n",
    "    embed_metric=cfg.embed_metric,\n",
    "    categorical_config=cat_config\n",
    ")\n",
    "val_dataset = AASPDataset(\n",
    "    config_path=config_path,\n",
    "    fields=selected_features,\n",
    "    fuse_mode=cfg.fuse_mode,\n",
    "    embed_metric=cfg.embed_metric,\n",
    "    categorical_config=cat_config\n",
    ")\n",
    "train_dataset.records = train_records\n",
    "val_dataset.records = val_records\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=cfg.hyperparameters[\"train_batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=cfg.hyperparameters[\"val_batch_size\"], shuffle=False)\n",
    "\n",
    "X, y = train_dataset[0]\n",
    "print(f\"Sample feature vector shape: {X.shape}\")\n",
    "print(f\"Sample label: {y}\")\n",
    "print(f\"Batch feature shape: {next(iter(train_loader))[0].shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd599e4",
   "metadata": {},
   "source": [
    "Actual Model Training Example\n",
    "================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5aa262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.src.aasp.model.models import BaselineModel\n",
    "from training.src.aasp.model.trainer import Trainer\n",
    "\n",
    "cat_dims = {k: (len(vocabs[k]), 4) for k, typ in cat_config.items() if typ == \"embedding\"}\n",
    "multi_hot_dims = {k: len(vocabs[k]) for k, typ in cat_config.items() if typ == \"multi_hot\"}\n",
    "\n",
    "model = BaselineModel(\n",
    "    input_dim=1,  # If \"distance\"\n",
    "    cat_dims=cat_dims,\n",
    "    multi_hot_dims=multi_hot_dims,\n",
    "    hidden_dims=tuple(cfg.hyperparameters[\"hidden_dims\"]),\n",
    "    dropout_rates=tuple(cfg.hyperparameters[\"dropout_rates\"])\n",
    ")\n",
    "print(model)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b28f305",
   "metadata": {},
   "source": [
    "Dumb Model Training Example\n",
    "================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68c8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.src.aasp.model.models import DumbModel\n",
    "from training.src.aasp.model.trainer import Trainer\n",
    "\n",
    "cat_dims = {k: (len(vocabs[k]), 4) for k, typ in cat_config.items() if typ == \"embedding\"}\n",
    "multi_hot_dims = {k: len(vocabs[k]) for k, typ in cat_config.items() if typ == \"multi_hot\"}\n",
    "\n",
    "model = DumbModel(\n",
    "    input_dim=1,  # If \"distance\"\n",
    "    cat_dims=cat_dims,\n",
    "    multi_hot_dims=multi_hot_dims,\n",
    "    hidden_dims=tuple(cfg.hyperparameters[\"hidden_dims\"]),\n",
    "    dropout_rates=tuple(cfg.hyperparameters[\"dropout_rates\"])\n",
    ")\n",
    "print(model)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12eef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg.hyperparameters[\"learning_rate\"])\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=cfg.hyperparameters[\"num_epochs\"],\n",
    "    save_path=\"output/baseline_model_best.pth\",\n",
    "    device= \"cuda\" if torch.cuda.is_available() else \"cpu\" # Change to \"cuda\" if GPU is available\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66798844",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
