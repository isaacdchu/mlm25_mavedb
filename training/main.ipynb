{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef591e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.src.aasp.data_handler.data_handler import AASPConfig, AASPDataHandler\n",
    "from training.src.aasp.data_handler.data_handler import AASPDataset\n",
    "\n",
    "config_path = \"training/src/aasp/data_handler/config.yaml\"\n",
    "cfg = AASPConfig(config_path)\n",
    "handler = AASPDataHandler(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfbf62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    k for k, v in getattr(cfg, \"features\", {}).items()\n",
    "    if v and k in {\"ref_embedding\", \"alt_embedding\", \"biotype\", \"consequence\", \"ref_long\", \"alt_long\", \"scoreset\"}\n",
    "]\n",
    "cat_config = getattr(cfg, \"categorical_config\", {})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbf69d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = handler.load_pickle(cfg.file_path)\n",
    "val_frac = cfg.parameters.get(\"val_frac\", 0.15)\n",
    "val_size = int(len(records) * val_frac)\n",
    "train_records = records[:len(records) - val_size]\n",
    "val_records = records[len(records) - val_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba730b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = {k: handler.fit_vocab(train_records, k) for k in cat_config}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ac4c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AASPDataset(\n",
    "    config_path=config_path,\n",
    "    fields=selected_features,\n",
    "    fuse_mode=cfg.fuse_mode,\n",
    "    embed_metric=cfg.embed_metric,\n",
    "    categorical_config=cat_config\n",
    ")\n",
    "val_dataset = AASPDataset(\n",
    "    config_path=config_path,\n",
    "    fields=selected_features,\n",
    "    fuse_mode=cfg.fuse_mode,\n",
    "    embed_metric=cfg.embed_metric,\n",
    "    categorical_config=cat_config\n",
    ")\n",
    "train_dataset.records = train_records\n",
    "val_dataset.records = val_records\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=cfg.hyperparameters[\"train_batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=cfg.hyperparameters[\"val_batch_size\"], shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd599e4",
   "metadata": {},
   "source": [
    "Actual Model Training Example\n",
    "================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5aa262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.src.aasp.model.models import BaselineModel\n",
    "from training.src.aasp.model.trainer import Trainer\n",
    "\n",
    "cat_dims = {k: (len(vocabs[k]), 4) for k, typ in cat_config.items() if typ == \"embedding\"}\n",
    "multi_hot_dims = {k: len(vocabs[k]) for k, typ in cat_config.items() if typ == \"multi_hot\"}\n",
    "\n",
    "model = BaselineModel(\n",
    "    input_dim=1,  # If \"distance\"\n",
    "    cat_dims=cat_dims,\n",
    "    multi_hot_dims=multi_hot_dims,\n",
    "    hidden_dims=tuple(cfg.hyperparameters[\"hidden_dims\"]),\n",
    "    dropout_rates=tuple(cfg.hyperparameters[\"dropout_rates\"])\n",
    ")\n",
    "\n",
    "import torch\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg.hyperparameters[\"learning_rate\"])\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=cfg.hyperparameters[\"num_epochs\"],\n",
    "    save_path=\"output/baseline_model_best.pth\",\n",
    "    device= \"cuda\" if torch.cuda.is_available() else \"cpu\" # Change to \"cuda\" if GPU is available\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b28f305",
   "metadata": {},
   "source": [
    "Dumb Model Training Example\n",
    "================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68c8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.src.aasp.model.models import DumbModel\n",
    "from training.src.aasp.model.trainer import Trainer\n",
    "\n",
    "cat_dims = {k: (len(vocabs[k]), 4) for k, typ in cat_config.items() if typ == \"embedding\"}\n",
    "multi_hot_dims = {k: len(vocabs[k]) for k, typ in cat_config.items() if typ == \"multi_hot\"}\n",
    "\n",
    "model = DumbModel(\n",
    "    input_dim=1,  # If \"distance\"\n",
    "    cat_dims=cat_dims,\n",
    "    multi_hot_dims=multi_hot_dims,\n",
    "    hidden_dims=tuple(cfg.hyperparameters[\"hidden_dims\"]),\n",
    "    dropout_rates=tuple(cfg.hyperparameters[\"dropout_rates\"])\n",
    ")\n",
    "\n",
    "import torch\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg.hyperparameters[\"learning_rate\"])\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=cfg.hyperparameters[\"num_epochs\"],\n",
    "    save_path=\"output/baseline_model_best.pth\",\n",
    "    device= \"cuda\" if torch.cuda.is_available() else \"cpu\" # Change to \"cuda\" if GPU is available\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66798844",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.run()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
