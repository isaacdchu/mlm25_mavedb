{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fef591e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.aasp.data_handler.data_handler import AASPConfig, AASPDataHandler\n",
    "from src.aasp.data_handler.aasp_dataset import AASPDataset\n",
    "\n",
    "config_path = \"config.yaml\" # Change this to config file path as needed and revert pathing in AASPConfig in data_handler.py\n",
    "cfg = AASPConfig(config_path)\n",
    "handler = AASPDataHandler(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cfbf62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    k for k, v in getattr(cfg, \"features\", {}).items()\n",
    "    if v and k in {\"ref_embedding\", \"alt_embedding\", \"biotype\", \"consequence\", \"ref_long\", \"alt_long\", \"scoreset\"}\n",
    "]\n",
    "cat_config = getattr(cfg, \"categorical_config\", {})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcbf69d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: c:\\Users\\ryanp\\Personal Projects\\mlm25_mavedb\\data\\train\\combined_train_data.pkl\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AASPConfig' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m records = handler.load_pickle(cfg.file_path)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m val_frac = \u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m.get(\u001b[33m\"\u001b[39m\u001b[33mval_frac\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0.15\u001b[39m)\n\u001b[32m      3\u001b[39m val_size = \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(records) * val_frac)\n\u001b[32m      4\u001b[39m train_records = records[:\u001b[38;5;28mlen\u001b[39m(records) - val_size]\n",
      "\u001b[31mAttributeError\u001b[39m: 'AASPConfig' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "records = handler.load_pickle(cfg.file_path)\n",
    "val_frac = cfg.parameters.get(\"val_frac\", 0.15)\n",
    "val_size = int(len(records) * val_frac)\n",
    "train_records = records[:len(records) - val_size]\n",
    "val_records = records[len(records) - val_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba730b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = {k: handler.fit_vocab(train_records, k) for k in cat_config}\n",
    "for k, vocab in vocabs.items():\n",
    "    print(f\"Vocab for {k}: {len(vocab)} classes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ac4c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AASPDataset(\n",
    "    config_path=config_path,\n",
    "    fields=selected_features,\n",
    "    fuse_mode=cfg.fuse_mode,\n",
    "    embed_metric=cfg.embed_metric,\n",
    "    categorical_config=cat_config\n",
    ")\n",
    "val_dataset = AASPDataset(\n",
    "    config_path=config_path,\n",
    "    fields=selected_features,\n",
    "    fuse_mode=cfg.fuse_mode,\n",
    "    embed_metric=cfg.embed_metric,\n",
    "    categorical_config=cat_config\n",
    ")\n",
    "train_dataset.records = train_records\n",
    "val_dataset.records = val_records\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=cfg.hyperparameters[\"train_batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=cfg.hyperparameters[\"val_batch_size\"], shuffle=False)\n",
    "\n",
    "X, y = train_dataset[0]\n",
    "print(f\"Sample feature vector shape: {X.shape}\")\n",
    "print(f\"Sample label: {y}\")\n",
    "print(f\"Batch feature shape: {next(iter(train_loader))[0].shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd599e4",
   "metadata": {},
   "source": [
    "Actual Model Training Example\n",
    "================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5aa262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.src.aasp.model.models import BaselineModel\n",
    "from training.src.aasp.model.trainer import Trainer\n",
    "\n",
    "cat_dims = {k: (len(vocabs[k]), 4) for k, typ in cat_config.items() if typ == \"embedding\"}\n",
    "multi_hot_dims = {k: len(vocabs[k]) for k, typ in cat_config.items() if typ == \"multi_hot\"}\n",
    "\n",
    "model = BaselineModel(\n",
    "    input_dim=1,  # If \"distance\"\n",
    "    cat_dims=cat_dims,\n",
    "    multi_hot_dims=multi_hot_dims,\n",
    "    hidden_dims=tuple(cfg.hyperparameters[\"hidden_dims\"]),\n",
    "    dropout_rates=tuple(cfg.hyperparameters[\"dropout_rates\"])\n",
    ")\n",
    "print(model)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b28f305",
   "metadata": {},
   "source": [
    "Dumb Model Training Example\n",
    "================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68c8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.src.aasp.model.models import DumbModel\n",
    "from training.src.aasp.model.trainer import Trainer\n",
    "\n",
    "cat_dims = {k: (len(vocabs[k]), 4) for k, typ in cat_config.items() if typ == \"embedding\"}\n",
    "multi_hot_dims = {k: len(vocabs[k]) for k, typ in cat_config.items() if typ == \"multi_hot\"}\n",
    "\n",
    "model = DumbModel(\n",
    "    input_dim=1,  # If \"distance\"\n",
    "    cat_dims=cat_dims,\n",
    "    multi_hot_dims=multi_hot_dims,\n",
    "    hidden_dims=tuple(cfg.hyperparameters[\"hidden_dims\"]),\n",
    "    dropout_rates=tuple(cfg.hyperparameters[\"dropout_rates\"])\n",
    ")\n",
    "print(model)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12eef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg.hyperparameters[\"learning_rate\"])\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=cfg.hyperparameters[\"num_epochs\"],\n",
    "    save_path=\"output/baseline_model_best.pth\",\n",
    "    device= \"cuda\" if torch.cuda.is_available() else \"cpu\" # Change to \"cuda\" if GPU is available\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66798844",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
